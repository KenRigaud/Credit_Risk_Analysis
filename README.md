# Credit_Risk_Analysis
Module 17 challenge

## Overview of the analysis:
The purpose of this analysis was to use machine learning libraries such as confusion matrices, forest features, and ensembles to analyze credit risk. We employed multiple models to compare results and choose the most effective approach in gauging ultimate credit risk.

## Results: 
* Random Forest is my preferred mode for machine learning over large sample sizes. It's balance accuracy score is great and very simple to code. The ease gives it an edge over most of the other tools on this list.
* Random Over Sampling feels is well suited for defining patterns and future prediction with random samples. I'd use this model as a secondary or supplemental step in the machine learning process as its balanced accuracy score is good though not great.
* Smote seems to use less resources for its machine learning algorithm. Though it gets the job done, its balance accuracy score pales in comparison to the better Smoteen model. It can definitely be used as a secondary check for credit risk.
* Cluster Centeroids is much easier to understand those its balance accuracy score could use a bit of work when compared to its more efficient brother/ sister models.
* Smoteenn is very effective at analyzing overall geometric mean. It achieved a strong balance accuracy score
* The ensemble balance accuracy score was by far the best

## Summary: 
Of all the model used in this challenge, I'd recomend the Ensemble Classifier as it gives the best balanced accuracy score. Though I usually go for ease of coding, accuracy in prediction is of utmost importance when it comes to assessing credit risk. A lot of money can be lost over a faulty prediction and nullifying that instance for error can help troubleshoot issues further down the road. It isn't perfect, but it is the most effective on the list provided. This challenge urges me on to find even more effective learning models employed by large firms like google, wells fargo, etc.
